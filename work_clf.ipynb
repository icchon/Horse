{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df3fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import preprocessing_mojule \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import preprocessing_mojule as pm\n",
    "from urllib.request import urlopen\n",
    "import pickle\n",
    "import japanize_matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcdf9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://db.netkeiba.com/race/\"\n",
    "\n",
    "def scraping_horse_ped(horse_id_dic, pre_horse_ped_dic={}):\n",
    "    horse_ped_dic = pre_horse_ped_dic.copy()\n",
    "    for horse_id, url in tqdm(horse_id_dic.items()):\n",
    "        try:\n",
    "            if horse_id in horse_ped_dic.keys():\n",
    "                continue\n",
    "            time.sleep(1)\n",
    "            res = requests.get(url)\n",
    "            res.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            li = soup.find(\"dd\", attrs={\"class\":\"DB_ProfHead_dd_01\"}).find_all(\"a\")\n",
    "            id_name_list = []\n",
    "            for i in li:\n",
    "                horse_name = i.get_text()\n",
    "                horse_parent_id = str(i).split(\"/\")[3]\n",
    "                id_name_list.append((horse_parent_id, horse_name))\n",
    "            dic = {}\n",
    "            dic[\"1_parent\"] = (id_name_list[0], id_name_list[3])\n",
    "            dic[\"2_parent\"] = (id_name_list[1], id_name_list[2], id_name_list[4], id_name_list[5])\n",
    "            horse_ped_dic[horse_id] = dic\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    return horse_ped_dic   \n",
    "\n",
    "def scraping_results(race_url_dic , pre_race_results={}):\n",
    "    time.sleep(0.5)\n",
    "    race_results = pre_race_results.copy()\n",
    "    for race_id, race_url in tqdm(race_url_dic.items()):\n",
    "        #time.sleep(1)\n",
    "        if race_id in race_results.keys():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            df_tmp = pd.read_html(race_url)[0]\n",
    "            res = requests.get(race_url)\n",
    "            res.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            texts_horse = soup.find(\"table\", summary=\"レース結果\").find_all(\"a\", attrs={\"href\":re.compile(\"/horse\")})\n",
    "            texts_jockey = soup.find(\"table\", summary=\"レース結果\").find_all(\"a\", attrs={\"href\":re.compile(\"/jockey\")})\n",
    "            horse_ids = []\n",
    "            jockey_ids = []\n",
    "            for text in texts_horse:\n",
    "                horse_id = re.findall(\"\\d+\", text[\"href\"])[0]\n",
    "                horse_ids.append(horse_id)\n",
    "            for text in texts_jockey:\n",
    "                jockey_id = re.findall(\"\\d+\", text[\"href\"])[0]\n",
    "                jockey_ids.append(jockey_id) \n",
    "            df_tmp[\"horse_id\"] = horse_ids\n",
    "            df_tmp[\"jockey_id\"] = jockey_ids\n",
    "            race_results[race_id] = df_tmp\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except:\n",
    "            print(race_url)\n",
    "            break \n",
    "    return race_results       \n",
    "\n",
    "def make_url():\n",
    "    url = \"https://db.netkeiba.com/race/\"\n",
    "    race_url_dic = {}\n",
    "    for place in range(1, 11):\n",
    "        for kai in range(1, 6):\n",
    "            for day in range(1, 13):\n",
    "                for race in range(1, 13):\n",
    "                    race_id = str(2023) + str(place).zfill(2) + str(kai).zfill(2) + str(day).zfill(2) + str(race).zfill(2)\n",
    "                    race_url_dic[race_id] = url + race_id\n",
    "    return race_url_dic            \n",
    "\n",
    "def dic_to_df(dic):\n",
    "    dic_tmp = dic.copy()\n",
    "    for key in dic_tmp:\n",
    "        dic_tmp[key].index = [key] * len(dic_tmp[key])\n",
    "    df = pd.concat([dic_tmp[key] for key in dic_tmp], sort=False)\n",
    "    return df\n",
    "\n",
    "def horse_pre_prizes_ave(x, gap=365):\n",
    "    horse_id = x[\"horse_id\"]\n",
    "    today = x[\"date\"]\n",
    "    first = True\n",
    "    try:\n",
    "        if horse_id not in dict_horse_history.keys():\n",
    "            return 0\n",
    "        df_horse = dict_horse_history[horse_id]\n",
    "        if isinstance(df_horse, pd.Series):\n",
    "            if today - df_horse[\"日付\"] > timedelta(gap) or today <= df_horse[\"日付\"]:\n",
    "                return 0\n",
    "            else:\n",
    "                average_prize = df_horse[\"賞金\"]\n",
    "        else:\n",
    "            df_horse_present = df_horse[today - df_horse[\"日付\"] <= timedelta(gap)]\n",
    "            df_horse_present = df_horse_present[today - df_horse_present[\"日付\"] > timedelta(0)]\n",
    "            df_horse_present_prize = df_horse_present[\"賞金\"]\n",
    "            average_prize = df_horse_present_prize.mean()\n",
    "        if np.isnan(average_prize):\n",
    "            return 0\n",
    "        else:\n",
    "            return average_prize\n",
    "    except KeyError:\n",
    "        if first:\n",
    "            first = False\n",
    "            print(f\"エラー race_id = {race_id}, horse_id = {horse_id}, today = {today}\")\n",
    "        return 0\n",
    "\n",
    "def horse_pre_prizes_sum(x, gap=365):\n",
    "    horse_id = x[\"horse_id\"]\n",
    "    today = x[\"date\"]\n",
    "    first = True\n",
    "    try:\n",
    "        if horse_id not in dict_horse_history.keys():\n",
    "            return 0\n",
    "        df_horse = dict_horse_history[horse_id]\n",
    "\n",
    "        if isinstance(df_horse, pd.Series):\n",
    "            if df_horse[\"日付\"] >= today or today - df_horse[\"日付\"] > timedelta(gap):\n",
    "                return 0\n",
    "            else:\n",
    "                average_prize = df_horse[\"賞金\"]\n",
    "        else:\n",
    "            df_horse_present = df_horse[today - df_horse[\"日付\"] <= timedelta(gap)]\n",
    "            df_horse_present = df_horse_present[today - df_horse_present[\"日付\"] > timedelta(0)]\n",
    "            df_horse_present_prize = df_horse_present[\"賞金\"]\n",
    "            average_prize = df_horse_present_prize.sum()\n",
    "\n",
    "        if np.isnan(average_prize):\n",
    "            return 0\n",
    "\n",
    "        else:\n",
    "            return average_prize\n",
    "    except KeyError:\n",
    "        if first:\n",
    "            first = False\n",
    "            print(f\"エラー race_id = {race_id}, horse_id = {horse_id}, today = {today}\")\n",
    "        return 0   \n",
    "\n",
    "\n",
    "def horse_pre_order_ave(x, gap=365):\n",
    "    def to_int(s):\n",
    "        try:\n",
    "            int(s)\n",
    "            return int(s)\n",
    "        except ValueError:\n",
    "            return substitute_num\n",
    "        \n",
    "    substitute_num = (sum([i+1 for i in range(16)])/16 + sum([i+1 for i in range(9)])/9) / 2\n",
    "    horse_id = x[\"horse_id\"]\n",
    "    today = x[\"date\"]\n",
    "    first = True\n",
    "    try:\n",
    "        if horse_id not in dict_horse_history.keys():\n",
    "            return substitute_num\n",
    "        df_horse = dict_horse_history[horse_id]\n",
    "\n",
    "        if isinstance(df_horse, pd.Series):\n",
    "            if df_horse[\"日付\"] >= today or today - df_horse[\"日付\"] > timedelta(gap):\n",
    "                return substitute_num\n",
    "            else:\n",
    "                average_order = to_int(df_horse[\"着順\"])\n",
    "                \n",
    "        else:\n",
    "            df_horse_present = df_horse[today - df_horse[\"日付\"] <= timedelta(gap)]\n",
    "            df_horse_present = df_horse_present[today - df_horse_present[\"日付\"] > timedelta(0)]\n",
    "            df_horse_present_order = df_horse_present[\"着順\"]\n",
    "            #df_horse_heads = df_horse_present[\"頭数\"]\n",
    "            df_horse_present_order = df_horse_present_order.map(lambda x:to_int(x))\n",
    "            #df_horse_heads = df_horse_heads.map(lambda x:to_int(x))\n",
    "            #df_horse_present_order = df_horse_present_order[df_horse_heads > 0]\n",
    "            #df_horse_heads = df_horse_heads[df_horse_heads > 0]\n",
    "            #average_order = df_horse_present_order / df_horse_heads\n",
    "            average_order = df_horse_present_order.mean()\n",
    "            \n",
    "\n",
    "        if np.isnan(average_order):\n",
    "            return substitute_num\n",
    "\n",
    "        else:\n",
    "            return average_order\n",
    "    except KeyError:\n",
    "        if first:\n",
    "            first = False\n",
    "            print(f\"エラー race_id = {race_id}, horse_id = {horse_id}, today = {today}\")\n",
    "        return substitute_num\n",
    "    \n",
    "\n",
    "class Results:\n",
    "    def __init__(self, pre_df):\n",
    "        self.pre_df = pre_df\n",
    "        self.before_scale = None\n",
    "        self.post_df = self.preprocessing(self.pre_df)\n",
    "        \n",
    "    \n",
    "    def preprocessing(self, pre_df):\n",
    "        results = pre_df.copy()\n",
    "        results = results[~(results[\"着順\"].astype(str).str.contains(\"\\D\"))]\n",
    "        results[\"着順\"] = results[\"着順\"].astype(int)\n",
    "        results[\"性齢\"] = results[\"性齢\"].astype(str)\n",
    "        results[\"性\"] = results[\"性齢\"].map(lambda x:x[0])\n",
    "        results[\"年齢\"] = results[\"性齢\"].map(lambda x:x[1:])\n",
    "        results[\"体重\"] = results[\"馬体重\"].map(lambda x:x[:3])\n",
    "        results[\"増減\"] = results[\"馬体重\"].str.split(\"(\").map(lambda x:int(x[-1][:-1]))\n",
    "        results[\"人気\"] = results[\"人気\"].astype(int)\n",
    "        results[\"年齢\"] = results[\"年齢\"].astype(int)\n",
    "        results[\"体重\"] = results[\"体重\"].astype(float)\n",
    "        results[\"単勝\"] = results[\"単勝\"].astype(float)\n",
    "        results = pd.concat([results, pd.get_dummies(results[\"性\"])], axis=1)\n",
    "        results[\"勝率*騎乗回数\"] = results[\"勝率\"] * results[\"騎乗回数\"]\n",
    "        results[\"連対率*騎乗回数\"] = results[\"連対率\"] * results[\"騎乗回数\"]\n",
    "        results[\"複勝率*騎乗回数\"] = results[\"複勝率\"] * results[\"騎乗回数\"]\n",
    "        \n",
    "        \n",
    "        results[\"増減/体重\"] = results[\"増減\"] / results[\"体重\"]  \n",
    "        results[\"斤量/体重\"] = results[\"斤量\"] / results[\"体重\"]\n",
    "        \n",
    "        features_addinfo = [\n",
    "            '着順', '枠番', '馬番', '馬名', '性齢', '斤量', '騎手', 'タイム', '着差', '単勝', '人気',\n",
    "       '馬体重', '調教師', 'horse_id', 'jockey_id', 'length', 'race_type', 'weather',\n",
    "       'condition', 'date', '騎乗回数', '勝率', '連対率', '複勝率', '賞金_ave', '賞金_sum',\n",
    "       '順番_ave', '賞金_ave_2', '賞金_sum_2', '順番_ave_2', '賞金_ave_4', '賞金_sum_4',\n",
    "       '順番_ave_4', '順番_ave_distorted', '順番_ave_2_distorted',\n",
    "       '順番_ave_4_distorted', '芝', 'ダ', '障', '短距離', 'マイル距離', '芝_ave_order',\n",
    "       'ダ_ave_order', '短距離_ave_order', 'マイル距離_ave_order', '芝得意', '短距離得意',\n",
    "       '中距離_ave_order', '長距離_ave_order', 'マイル距離得意', '中距離得意', '長距離得意',\n",
    "       'length_match', 'race_type_match'\n",
    "        ]\n",
    "        \n",
    "        drop_features = [\n",
    "            \"枠番\", \"馬名\", \"性齢\", \"騎手\", \"タイム\", \"着差\", \"人気\", \"馬体重\", \"調教師\", \"horse_id\",\n",
    "            \"jockey_id\", \"length\", \"race_type\", \"weather\", \"condition\", \"date\", \"性\",\n",
    "            '芝', 'ダ', '障', '短距離', 'マイル距離', '芝_ave_order',\n",
    "            'ダ_ave_order', '短距離_ave_order', 'マイル距離_ave_order', '芝得意', '短距離得意',\n",
    "            '中距離_ave_order', '長距離_ave_order', 'マイル距離得意', '中距離得意', '長距離得意',\n",
    "        ]\n",
    "        results = results.drop(drop_features, axis=1)\n",
    "        results = results.astype(float)\n",
    "        results[\"着順\"] = results[\"着順\"].astype(int)\n",
    "        self.before_scale = results\n",
    "        \n",
    "        keep_features = ['着順', 'セ', '牝', '牡', \"馬番\", \"length_match\", \"race_type_match\"]\n",
    "        scaler = pm.CustomSTDScaler(keep_features)\n",
    "        results = scaler.fit_transform(results)\n",
    "    \n",
    "        return results\n",
    " \n",
    "\n",
    "def scraping_infos(race_url_dic , pre_race_infos={}):\n",
    "    time.sleep(1)\n",
    "    race_infos = pre_race_infos.copy()\n",
    "    for race_id, race_url in tqdm(race_url_dic.items()):\n",
    "        if race_id in race_infos.keys():\n",
    "            continue\n",
    "        try:\n",
    "            res = requests.get(race_url)\n",
    "            res.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            texts = soup.find(\"div\", attrs={\"class\":\"data_intro\"}).find_all(\"p\")[0].get_text() + soup.find(\"div\", attrs={\"class\":\"data_intro\"}).find_all(\"p\")[1].get_text()\n",
    "            texts = re.findall(r\"\\w+\", texts)\n",
    "            race_infos[race_id] = {}\n",
    "            for idx, text in enumerate(texts):\n",
    "                if text in [\"芝\" , \"ダート\"]:\n",
    "                    race_infos[race_id][\"condition\"] = texts[idx + 1]\n",
    "                if text in [\"天候\"]:\n",
    "                    race_infos[race_id][\"weather\"] = texts[idx + 1]\n",
    "                for date in [str(i) for i in range(2000, 2025)]:\n",
    "                    if date in text:\n",
    "                        race_infos[race_id][\"date\"] = text\n",
    "                if \"m\" in text:\n",
    "                    race_infos[race_id][\"length\"] = text[-5:-1]\n",
    "                if \"race_type\" in race_infos[race_id].keys() and race_infos[race_id][\"race_type\"] == \"障\":\n",
    "                    continue\n",
    "                for race_type in [\"障\", \"芝\", \"ダート\"]:\n",
    "                    if race_type in text:\n",
    "                        race_infos[race_id][\"race_type\"] = race_type\n",
    "\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        except:\n",
    "            print(race_url)\n",
    "            break \n",
    "    return race_infos \n",
    "\n",
    "def scraping_horse(horse_id_dic, pre_horse_history={}):\n",
    "    horse_history = pre_horse_history.copy()\n",
    "    time.sleep(1)\n",
    "    for horse_id, horse_url in tqdm(horse_id_dic.items()):\n",
    "        tmp_df = pd.read_html(horse_url)[3]\n",
    "        horse_history[horse_id] = tmp_df\n",
    "    return horse_history    \n",
    "\n",
    "def make_horse_url(horse_id_list):\n",
    "    horse_id_dic = {}\n",
    "    for horse_id in horse_id_list:\n",
    "        horse_url = \"https://db.netkeiba.com/\" + \"horse/\" + str(horse_id)\n",
    "        horse_id_dic[horse_id] = horse_url\n",
    "        \n",
    "    return horse_id_dic\n",
    "\n",
    "def scraping_jockey(jockey_id_dic, pre_jockey_history):\n",
    "    jockey_history = pre_jockey_history.copy()\n",
    "    for jockey_id, jockey_url in tqdm(jockey_id_dic.items()):\n",
    "        time.sleep(1)\n",
    "        tmp_df = pd.read_html(jockey_url)[2]\n",
    "        jockey_history[jockey_id] = tmp_df\n",
    "        \n",
    "    return jockey_history    \n",
    "\n",
    "def make_jockey_url(jockey_id_list):\n",
    "    jockey_id_dic = {}\n",
    "    for jockey_id in jockey_id_list:\n",
    "        jockey_url = \"https://db.netkeiba.com/\" + \"jockey/\" + str(jockey_id)\n",
    "        jockey_id_dic[jockey_id] = jockey_url\n",
    "        \n",
    "    return jockey_id_dic   \n",
    "\n",
    "def scraping_pay(race_url_dic, pre_pay={}):\n",
    "    pay = pre_pay.copy()\n",
    "    for race_id, url in tqdm(race_url_dic.items()):\n",
    "        if race_id in pay.keys():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            time.sleep(0.1)\n",
    "            f = urlopen(url)\n",
    "            html = f.read()\n",
    "            html = html.replace(b\"<br />\", b\"br\")\n",
    "            df = pd.concat([pd.read_html(html)[1], pd.read_html(html)[2]], axis=0)\n",
    "            df.columns = [\"種類\", \"該当馬\", \"金\", \"人気\"]\n",
    "            df.set_index(\"種類\", inplace=True)\n",
    "            df[\"人気\"] = df[\"人気\"].map(lambda x:re.split(\"br|-|→\", x))\n",
    "            df[\"該当馬\"] = df[\"該当馬\"].map(lambda x:re.split(\"br|-|→\", x))\n",
    "            df[\"金\"] = df[\"金\"].map(lambda x:re.split(\"br|-|→\", x))\n",
    "            pay[race_id] = df\n",
    "        except UnicodeDecodeError:\n",
    "            print((race_id, url))\n",
    "            continue\n",
    "        except IndexError:\n",
    "            print((race_id, url))\n",
    "            continue\n",
    "        except:\n",
    "            print((race_id, url))\n",
    "            break\n",
    "    return pay\n",
    "\n",
    "class Evaluater():\n",
    "    def __init__(self, X, y):\n",
    "        train_x, self.__X_test, train_y, self.__y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "        self.__X_train, self.__X_val, self.__y_train, self.__y_val = train_test_split(train_x, train_y, test_size=0.3, shuffle=False)\n",
    "        self.__params = None\n",
    "        self.__params = self.params\n",
    "        self.__model = self.model\n",
    "        return \n",
    "    @property\n",
    "    def params(self):\n",
    "        if self.__params == None:\n",
    "            param = {\n",
    "                'objective': 'binary',\n",
    "                 'random_state': 57,\n",
    "                 'metric': 'auc',\n",
    "                 'feature_pre_filter': False,\n",
    "                 'lambda_l1': 9.926347819260023,\n",
    "                 'lambda_l2': 0.2635745692891133,\n",
    "                 'num_leaves': 2,\n",
    "                 'feature_fraction': 0.48000000000000004,\n",
    "                 'bagging_fraction': 1.0,\n",
    "                 'bagging_freq': 0,\n",
    "                 'min_child_samples': 20,\n",
    "                 'num_iterations': 1000\n",
    "            }\n",
    "         \n",
    "        self.__params = param\n",
    "        return self.__params\n",
    "    @params.setter\n",
    "    def params(self, params):\n",
    "        self.__params = params\n",
    "        self.__model = lgb.LGBMClassifier(**self.__params, verbose=-1)\n",
    "    @property\n",
    "    def model(self):\n",
    "        self.__model = lgb.LGBMClassifier(**self.__params, verbose=-1)\n",
    "        return self.__model\n",
    "    @property\n",
    "    def X_test(self):\n",
    "        return self.__X_test\n",
    "    def predict(self,X_test, threshold=0.5):\n",
    "        self.fit()\n",
    "        pred = self.predict_proba(X_test, threshold)\n",
    "        pred = np.array([1 if p >= threshold else 0 for p in pred])\n",
    "        return pred\n",
    "    def predict_proba(self, X_test, threshold=0.5):\n",
    "        self.fit()\n",
    "        pred = self.__model.predict_proba(X_test.drop([\"馬番\", \"単勝\"], axis=1, inplace=False)).T[1]\n",
    "        df = X_test.copy()\n",
    "        df[\"proba\"] = pred\n",
    "        df[\"mean\"] = df.groupby(df.index)[\"proba\"].transform(\"mean\")\n",
    "        df[\"std\"] = df.groupby(df.index)[\"proba\"].transform(\"std\")\n",
    "        df[\"min\"] = df.groupby(df.index)[\"proba\"].transform(\"min\")\n",
    "        df[\"max\"] = df.groupby(df.index)[\"proba\"].transform(\"max\")\n",
    "        df[\"scale_standard\"] = (df[\"proba\"] - df[\"mean\"]) / df[\"std\"]\n",
    "        df[\"scale_minmax\"] = (df[\"proba\"] - df[\"min\"]) / (df[\"max\"] - df[\"min\"])\n",
    "        return df[\"scale_standard\"]\n",
    "    def fit(self):\n",
    "        verbose_eval = -1\n",
    "        self.__model = self.__model.fit(self.__X_train.drop([\"馬番\", \"単勝\"], axis=1, inplace=False), self.__y_train,\n",
    "                 eval_set=[(self.__X_val.drop([\"馬番\", \"単勝\"], axis=1, inplace=False), self.__y_val)],\n",
    "                 callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False), \n",
    "                            lgb.log_evaluation(verbose_eval),\n",
    "                          ] \n",
    "                 )\n",
    "        return self.__model\n",
    "    def f1_score_cal(self,threshold=0.5):\n",
    "        pred = self.predict(self.__X_test, threshold)\n",
    "        return f1_score(self.__y_test, pred)\n",
    "    def acc_cal(self, threshold=0.5):\n",
    "        pred = self.predict(self.__X_test, threshold)\n",
    "        return accuracy_score(self.__y_test, pred)\n",
    "    def importance(self):\n",
    "        self.fit()\n",
    "        importances = pd.DataFrame(\n",
    "            {\n",
    "                \"features\":self.__X_train.drop([\"馬番\", \"単勝\"], axis=1, inplace=False).columns, \"importance\":self.__model.feature_importances_\n",
    "            })\n",
    "            \n",
    "        importances =  importances.sort_values(\"importance\", ascending=False)\n",
    "        return importances\n",
    "    def cal(self, X_test, pay_dict, threshold=0.5, fukusho=False, balanced=True):\n",
    "        def cal_payment(x):\n",
    "            race_id = x.name\n",
    "            horse_number = str(int(x[0]))\n",
    "            odds = x[1]\n",
    "            df = pay_dict[race_id]\n",
    "            df_fukusho = df.loc[\"複勝\"]\n",
    "            df_tansho = df.loc[\"単勝\"]\n",
    "            money = 0\n",
    "            if balanced == False:\n",
    "                if horse_number in df_fukusho[\"該当馬\"] and fukusho:\n",
    "                    idx = df_fukusho[\"該当馬\"].index(horse_number)\n",
    "                    tmp = df_fukusho[\"金\"][idx]\n",
    "                    tmp = tmp.split(\",\")\n",
    "                    money = int(\"\".join(tmp))\n",
    "                if horse_number in df_tansho[\"該当馬\"] and fukusho == False:\n",
    "                    tmp = df_tansho[\"金\"][0]\n",
    "                    tmp = tmp.split(\",\")\n",
    "                    money = int(\"\".join(tmp))\n",
    "            else:\n",
    "                if horse_number in df_fukusho[\"該当馬\"] and fukusho:\n",
    "                    idx = df_fukusho[\"該当馬\"].index(horse_number)\n",
    "                    tmp = df_fukusho[\"金\"][idx]\n",
    "                    tmp = tmp.split(\",\")\n",
    "                    odds_post = int(\"\".join(tmp))\n",
    "                    n_parchased = 10000 // (odds*0.5*100)\n",
    "                    money = n_parchased * odds_post \n",
    "                if horse_number in df_tansho[\"該当馬\"] and fukusho == False:\n",
    "                    tmp = df_tansho[\"金\"][0]\n",
    "                    tmp = tmp.split(\",\")\n",
    "                    odds_post = int(\"\".join(tmp))\n",
    "                    n_parchased = 10000 // (odds*100)\n",
    "                    money = n_parchased * odds_post \n",
    "                    \n",
    "            return money\n",
    "        def cal_invested(x):\n",
    "            race_id = x.name\n",
    "            horse_number = str(int(x[0]))\n",
    "            odds = x[1]\n",
    "            if fukusho == False:\n",
    "                n_parchased = 10000 // (odds*100)\n",
    "            else:\n",
    "                n_parchased = 10000 // (odds*0.5*100)\n",
    "            invested = n_parchased * 100    \n",
    "            return invested\n",
    "            \n",
    "        pred = self.predict(X_test, threshold)\n",
    "        parchaced = X_test[pred==1][[\"馬番\", \"単勝\"]]\n",
    "        payback = parchaced.apply(lambda x:cal_payment(x), axis=1)\n",
    "        payback_sum = np.sum(payback.values, axis=0)\n",
    "        if balanced == False:\n",
    "            invested = 100 * parchaced.shape[0]\n",
    "        else:\n",
    "            tmp = parchaced.apply(lambda x:cal_invested(x), axis=1)\n",
    "            invested = np.sum(tmp.values, axis=0)\n",
    "        div = payback_sum - invested\n",
    "        if isinstance(invested, (int, float)):\n",
    "            if invested == 0:\n",
    "                div = 0\n",
    "                payback_sum = 0\n",
    "        else:\n",
    "            invested = 0\n",
    "            div = 0\n",
    "            payback_sum = 0\n",
    "            \n",
    "        return invested, payback_sum, payback\n",
    "    def visualize(self, X_test, bins=100, fukusho=False, balanced=True):\n",
    "        thresholds = []\n",
    "        kaishuuritu = []\n",
    "        div = []\n",
    "        investeds = []\n",
    "        stds = []\n",
    "        res = {}\n",
    "        for i in tqdm(range(bins+2)):\n",
    "            threshold = -1 + (i/bins)*3\n",
    "            thresholds.append(threshold)\n",
    "            invested, payback_sum, payback = self.cal(X_test, pay_dict, threshold, fukusho, balanced)\n",
    "            std = payback.std() / np.sqrt(payback.shape[0])\n",
    "            div.append(payback_sum - invested)\n",
    "            investeds.append(invested/100)\n",
    "            if invested == 0:\n",
    "                if payback_sum == 0:\n",
    "                    kaishuuritu.append(1*100)    \n",
    "                stds.append(stds[-1])\n",
    "                continue\n",
    "            stds.append(std)    \n",
    "            kaishuuritu.append((payback_sum / invested)*100)\n",
    "        res[\"invested\"] = np.array(investeds)\n",
    "        res[\"kaishuuritu\"] = np.array(kaishuuritu)\n",
    "        res[\"div\"] = np.array(div)\n",
    "        res[\"threshold\"] = np.array(thresholds)\n",
    "        res[\"std\"] = np.array(stds)\n",
    "        self.__d = res[\"invested\"]\n",
    "        self.__h = res[\"kaishuuritu\"]\n",
    "        return res   \n",
    "    def integral(self, d=None, h=None, bins=100, fukusho=True):\n",
    "        def private_integral(x, y):\n",
    "            z = [(d, h) for d, h in zip(x, y)]\n",
    "            z.sort()\n",
    "            x = np.array([i[0] for i in z])\n",
    "            x = x/max(x)\n",
    "            y = np.array([i[1] for i in z])\n",
    "            y = y - 100\n",
    "\n",
    "            length = x.shape[0]\n",
    "            S = 0\n",
    "            for i in range(length - 1):\n",
    "                d = x[i + 1] - x[i]\n",
    "                a = y[i]\n",
    "                b = y[i + 1]\n",
    "                s = (y[i] + y[i + 1]) * d / 2\n",
    "                S += s\n",
    "            return S   \n",
    "        if d is None is h == None:\n",
    "            res = self.visualize(self.X_test, bins=bins, fukusho=fukusho)\n",
    "            d, h = res[\"invested\"], res[\"kaishuuritu\"]\n",
    "        return private_integral(d, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e557128",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_addinfo = pd.read_pickle(\"result_addinfo.pickle\")\n",
    "horse_history = pd.read_pickle(\"horse_history.pickle\")\n",
    "jockey_history = pd.read_pickle(\"jockey_history.pickle\")\n",
    "dict_horse_history = {idx: horse_history.loc[idx] for idx in horse_history.index.unique()}\n",
    "\n",
    "with open(\"pay_dict.pickle\", \"rb\") as f:\n",
    "    pay_dict = pickle.load(f)\n",
    "with open(\"dict_horse_ped.pickle\", \"rb\") as f:\n",
    "    horse_ped_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "340729b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "instance = Results(results_addinfo)\n",
    "data = instance.post_df\n",
    "th = 3\n",
    "X, y = data.drop([\"着順\"], axis=1), data[\"着順\"].map(lambda x:1 if -(x-th) >= 0 else 0)\n",
    "\n",
    "drop_features = [\n",
    "       '連対率', \n",
    "        '賞金_ave_2', '賞金_sum_2',  '賞金_ave_4', '賞金_sum_4',\n",
    "        '順番_ave_4', '順番_ave_distorted', '順番_ave_2_distorted',\n",
    "        '順番_ave_4_distorted',\n",
    "        '増減',  '勝率*騎乗回数',\n",
    "        '連対率*騎乗回数', '複勝率*騎乗回数',\n",
    "]\n",
    "X.drop(drop_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "781cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = Evaluater(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5d85451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>賞金_ave</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>順番_ave</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>複勝率</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>年齢</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>順番_ave_2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>斤量</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>length_match</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>斤量/体重</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>賞金_sum</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>増減/体重</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>勝率</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>horse_ped_score</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>体重</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>騎乗回数</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>セ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>牝</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>牡</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>race_type_match</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           features  importance\n",
       "4            賞金_ave          57\n",
       "6            順番_ave          51\n",
       "3               複勝率          42\n",
       "11               年齢          34\n",
       "7          順番_ave_2          25\n",
       "0                斤量          22\n",
       "8      length_match          17\n",
       "17            斤量/体重          17\n",
       "5            賞金_sum          11\n",
       "16            増減/体重          11\n",
       "2                勝率           9\n",
       "10  horse_ped_score           6\n",
       "12               体重           3\n",
       "1              騎乗回数           0\n",
       "13                セ           0\n",
       "14                牝           0\n",
       "15                牡           0\n",
       "9   race_type_match           0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5add48b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef5bd05b77342e284cf22eaac497afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "dic2 = ev.visualize(ev.X_test, fukusho=False, bins=30, balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "383e193c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 0\n",
    "#plt.plot(dic3[\"invested\"], dic3[\"kaishuuritu\"], label=\"前のやつ\")\n",
    "plt.plot(dic2[\"invested\"], dic2[\"kaishuuritu\"], label=\"今のやつ\")\n",
    "#plt.fill_between(dic[\"invested\"], dic[\"kaishuuritu\"] - a*dic[\"std\"], dic[\"kaishuuritu\"] + a*dic[\"std\"], alpha=0.2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"投資枚数\")\n",
    "plt.ylabel(\"回収率\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ffd4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d576143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be75208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4374e328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39a03dead9a4402b0c0f7ee849fc24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kanat\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "accs = []\n",
    "f1s = []\n",
    "for i in tqdm(range(12)):\n",
    "    th = i / 10\n",
    "    thresholds.append(th)\n",
    "    acc = ev.acc_cal(th)\n",
    "    f1 = ev.f1_score_cal(th)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "8a1d586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x, y_train, tmp_y, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(tmp_x, tmp_y, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "8dac2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb_o\n",
    "lgb_train = lgb_o.Dataset(X_train.values, y_train.values)\n",
    "lgb_val = lgb_o.Dataset(X_val.values, y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "19b81960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 02:59:37,118] A new study created in memory with name: no-name-b7603ce8-5ec8-4041-859a-d896353c6308\n",
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.803047:  14%|######4                                      | 1/7 [00:05<00:31,  5.30s/it][I 2023-12-18 02:59:42,437] Trial 0 finished with value: 0.8030465879909442 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.8030465879909442.\n",
      "feature_fraction, val_score: 0.803047:  14%|######4                                      | 1/7 [00:05<00:31,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.803047:  29%|############8                                | 2/7 [00:10<00:27,  5.41s/it][I 2023-12-18 02:59:47,935] Trial 1 finished with value: 0.8005043898883852 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.8030465879909442.\n",
      "feature_fraction, val_score: 0.803047:  29%|############8                                | 2/7 [00:10<00:27,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.803047:  43%|###################2                         | 3/7 [00:16<00:22,  5.55s/it][I 2023-12-18 02:59:53,635] Trial 2 finished with value: 0.7977604131746282 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8030465879909442.\n",
      "feature_fraction, val_score: 0.803047:  43%|###################2                         | 3/7 [00:16<00:22,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.803047:  57%|#########################7                   | 4/7 [00:22<00:17,  5.77s/it][I 2023-12-18 02:59:59,740] Trial 3 finished with value: 0.8014305183140286 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.8030465879909442.\n",
      "feature_fraction, val_score: 0.803047:  57%|#########################7                   | 4/7 [00:22<00:17,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.803047:  71%|################################1            | 5/7 [00:28<00:11,  5.91s/it][I 2023-12-18 03:00:05,906] Trial 4 finished with value: 0.800274928667721 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.8030465879909442.\n",
      "feature_fraction, val_score: 0.803047:  71%|################################1            | 5/7 [00:28<00:11,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.803047:  86%|######################################5      | 6/7 [00:35<00:06,  6.05s/it][I 2023-12-18 03:00:12,223] Trial 5 finished with value: 0.7954105065485655 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.8030465879909442.\n",
      "feature_fraction, val_score: 0.803047:  86%|######################################5      | 6/7 [00:35<00:06,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.803047: 100%|#############################################| 7/7 [00:40<00:00,  5.98s/it][I 2023-12-18 03:00:18,074] Trial 6 finished with value: 0.7998242897693784 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.8030465879909442.\n",
      "feature_fraction, val_score: 0.803047: 100%|#############################################| 7/7 [00:40<00:00,  5.85s/it]\n",
      "num_leaves, val_score: 0.803047:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.803047:   5%|##5                                               | 1/20 [00:07<02:24,  7.58s/it][I 2023-12-18 03:00:25,669] Trial 7 finished with value: 0.7972328152059796 and parameters: {'num_leaves': 71}. Best is trial 7 with value: 0.7972328152059796.\n",
      "num_leaves, val_score: 0.803047:   5%|##5                                               | 1/20 [00:07<02:24,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.803047:  10%|#####                                             | 2/20 [00:20<03:09, 10.52s/it][I 2023-12-18 03:00:38,249] Trial 8 finished with value: 0.7961970891346749 and parameters: {'num_leaves': 166}. Best is trial 7 with value: 0.7972328152059796.\n",
      "num_leaves, val_score: 0.803047:  10%|#####                                             | 2/20 [00:20<03:09, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.803047:  15%|#######5                                          | 3/20 [00:29<02:48,  9.92s/it][I 2023-12-18 03:00:47,462] Trial 9 finished with value: 0.7988626907878719 and parameters: {'num_leaves': 99}. Best is trial 9 with value: 0.7988626907878719.\n",
      "num_leaves, val_score: 0.803047:  15%|#######5                                          | 3/20 [00:29<02:48,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.803047:  20%|##########                                        | 4/20 [00:46<03:22, 12.67s/it][I 2023-12-18 03:01:04,351] Trial 10 finished with value: 0.7939832591720237 and parameters: {'num_leaves': 244}. Best is trial 9 with value: 0.7988626907878719.\n",
      "num_leaves, val_score: 0.803047:  20%|##########                                        | 4/20 [00:46<03:22, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.804546:  25%|############5                                     | 5/20 [00:50<02:25,  9.68s/it][I 2023-12-18 03:01:08,717] Trial 11 finished with value: 0.8045461216699538 and parameters: {'num_leaves': 13}. Best is trial 11 with value: 0.8045461216699538.\n",
      "num_leaves, val_score: 0.804546:  25%|############5                                     | 5/20 [00:50<02:25,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  30%|###############                                   | 6/20 [00:54<01:48,  7.73s/it][I 2023-12-18 03:01:12,655] Trial 12 finished with value: 0.8093343635134428 and parameters: {'num_leaves': 7}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  30%|###############                                   | 6/20 [00:54<01:48,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  35%|#################5                                | 7/20 [00:59<01:28,  6.83s/it][I 2023-12-18 03:01:17,631] Trial 13 finished with value: 0.8038183734788991 and parameters: {'num_leaves': 15}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  35%|#################5                                | 7/20 [00:59<01:28,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  40%|####################                              | 8/20 [01:03<01:11,  5.92s/it][I 2023-12-18 03:01:21,601] Trial 14 finished with value: 0.8088921497571117 and parameters: {'num_leaves': 8}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  40%|####################                              | 8/20 [01:03<01:11,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  45%|######################5                           | 9/20 [01:08<01:00,  5.47s/it][I 2023-12-18 03:01:26,096] Trial 15 finished with value: 0.8047552634304729 and parameters: {'num_leaves': 16}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  45%|######################5                           | 9/20 [01:08<01:00,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  50%|########################5                        | 10/20 [01:15<00:59,  6.00s/it][I 2023-12-18 03:01:33,269] Trial 16 finished with value: 0.7996996826270244 and parameters: {'num_leaves': 60}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  50%|########################5                        | 10/20 [01:15<00:59,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  55%|##########################9                      | 11/20 [01:27<01:10,  7.79s/it][I 2023-12-18 03:01:45,123] Trial 17 finished with value: 0.7982006445446037 and parameters: {'num_leaves': 153}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  55%|##########################9                      | 11/20 [01:27<01:10,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  60%|#############################4                   | 12/20 [01:33<00:59,  7.49s/it][I 2023-12-18 03:01:51,933] Trial 18 finished with value: 0.7995296221975163 and parameters: {'num_leaves': 56}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  60%|#############################4                   | 12/20 [01:33<00:59,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  65%|###############################8                 | 13/20 [01:48<01:07,  9.68s/it][I 2023-12-18 03:02:06,662] Trial 19 finished with value: 0.79669523450604 and parameters: {'num_leaves': 207}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  65%|###############################8                 | 13/20 [01:48<01:07,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  70%|##################################3              | 14/20 [01:58<00:58,  9.68s/it][I 2023-12-18 03:02:16,334] Trial 20 finished with value: 0.7982185568213171 and parameters: {'num_leaves': 110}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  70%|##################################3              | 14/20 [01:58<00:58,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.809334:  75%|####################################7            | 15/20 [02:02<00:40,  8.01s/it][I 2023-12-18 03:02:20,472] Trial 21 finished with value: 0.8078376618149412 and parameters: {'num_leaves': 9}. Best is trial 12 with value: 0.8093343635134428.\n",
      "num_leaves, val_score: 0.809334:  75%|####################################7            | 15/20 [02:02<00:40,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820601:  80%|#######################################2         | 16/20 [02:06<00:26,  6.69s/it][I 2023-12-18 03:02:24,083] Trial 22 finished with value: 0.820601079366891 and parameters: {'num_leaves': 2}. Best is trial 22 with value: 0.820601079366891.\n",
      "num_leaves, val_score: 0.820601:  80%|#######################################2         | 16/20 [02:06<00:26,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820601:  85%|#########################################6       | 17/20 [02:13<00:20,  6.85s/it][I 2023-12-18 03:02:31,312] Trial 23 finished with value: 0.801376639884863 and parameters: {'num_leaves': 45}. Best is trial 22 with value: 0.820601079366891.\n",
      "num_leaves, val_score: 0.820601:  85%|#########################################6       | 17/20 [02:13<00:20,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820601:  90%|############################################1    | 18/20 [02:20<00:13,  6.95s/it][I 2023-12-18 03:02:38,492] Trial 24 finished with value: 0.7998555123544796 and parameters: {'num_leaves': 37}. Best is trial 22 with value: 0.820601079366891.\n",
      "num_leaves, val_score: 0.820601:  90%|############################################1    | 18/20 [02:20<00:13,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820601:  95%|##############################################5  | 19/20 [02:28<00:07,  7.38s/it][I 2023-12-18 03:02:46,875] Trial 25 finished with value: 0.8008207929106466 and parameters: {'num_leaves': 75}. Best is trial 22 with value: 0.820601079366891.\n",
      "num_leaves, val_score: 0.820601:  95%|##############################################5  | 19/20 [02:28<00:07,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820601: 100%|#################################################| 20/20 [02:34<00:00,  6.86s/it][I 2023-12-18 03:02:52,540] Trial 26 finished with value: 0.8024821742756909 and parameters: {'num_leaves': 33}. Best is trial 22 with value: 0.820601079366891.\n",
      "num_leaves, val_score: 0.820601: 100%|#################################################| 20/20 [02:34<00:00,  7.72s/it]\n",
      "bagging, val_score: 0.820601:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  10%|#####3                                               | 1/10 [00:03<00:34,  3.78s/it][I 2023-12-18 03:02:56,337] Trial 27 finished with value: 0.820275224609684 and parameters: {'bagging_fraction': 0.9491396061675355, 'bagging_freq': 2}. Best is trial 27 with value: 0.820275224609684.\n",
      "bagging, val_score: 0.820601:  10%|#####3                                               | 1/10 [00:03<00:34,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  20%|##########6                                          | 2/10 [00:07<00:30,  3.78s/it][I 2023-12-18 03:03:00,118] Trial 28 finished with value: 0.8204088940896638 and parameters: {'bagging_fraction': 0.9647320185908103, 'bagging_freq': 2}. Best is trial 28 with value: 0.8204088940896638.\n",
      "bagging, val_score: 0.820601:  20%|##########6                                          | 2/10 [00:07<00:30,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  30%|###############9                                     | 3/10 [00:11<00:26,  3.77s/it][I 2023-12-18 03:03:03,883] Trial 29 finished with value: 0.8203872294387772 and parameters: {'bagging_fraction': 0.9768626107307689, 'bagging_freq': 2}. Best is trial 28 with value: 0.8204088940896638.\n",
      "bagging, val_score: 0.820601:  30%|###############9                                     | 3/10 [00:11<00:26,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  40%|#####################2                               | 4/10 [00:15<00:23,  3.84s/it][I 2023-12-18 03:03:07,810] Trial 30 finished with value: 0.8203249258676002 and parameters: {'bagging_fraction': 0.9869727773138708, 'bagging_freq': 2}. Best is trial 28 with value: 0.8204088940896638.\n",
      "bagging, val_score: 0.820601:  40%|#####################2                               | 4/10 [00:15<00:23,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  50%|##########################5                          | 5/10 [00:19<00:19,  3.85s/it][I 2023-12-18 03:03:11,677] Trial 31 finished with value: 0.8199950709379258 and parameters: {'bagging_fraction': 0.9654602727965308, 'bagging_freq': 2}. Best is trial 28 with value: 0.8204088940896638.\n",
      "bagging, val_score: 0.820601:  50%|##########################5                          | 5/10 [00:19<00:19,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  60%|###############################8                     | 6/10 [00:22<00:15,  3.82s/it][I 2023-12-18 03:03:15,451] Trial 32 finished with value: 0.8202008143218352 and parameters: {'bagging_fraction': 0.9839977474409556, 'bagging_freq': 2}. Best is trial 28 with value: 0.8204088940896638.\n",
      "bagging, val_score: 0.820601:  60%|###############################8                     | 6/10 [00:22<00:15,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  70%|#####################################                | 7/10 [00:26<00:11,  3.77s/it][I 2023-12-18 03:03:19,126] Trial 33 finished with value: 0.8203991945564237 and parameters: {'bagging_fraction': 0.997115202782193, 'bagging_freq': 6}. Best is trial 28 with value: 0.8204088940896638.\n",
      "bagging, val_score: 0.820601:  70%|#####################################                | 7/10 [00:26<00:11,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  80%|##########################################4          | 8/10 [00:30<00:07,  3.71s/it][I 2023-12-18 03:03:22,710] Trial 34 finished with value: 0.8204180980263149 and parameters: {'bagging_fraction': 0.6880917734172864, 'bagging_freq': 7}. Best is trial 34 with value: 0.8204180980263149.\n",
      "bagging, val_score: 0.820601:  80%|##########################################4          | 8/10 [00:30<00:07,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601:  90%|###############################################7     | 9/10 [00:33<00:03,  3.74s/it][I 2023-12-18 03:03:26,493] Trial 35 finished with value: 0.8202534891592849 and parameters: {'bagging_fraction': 0.6637688931523749, 'bagging_freq': 7}. Best is trial 34 with value: 0.8204180980263149.\n",
      "bagging, val_score: 0.820601:  90%|###############################################7     | 9/10 [00:33<00:03,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.820601: 100%|####################################################| 10/10 [00:37<00:00,  3.67s/it][I 2023-12-18 03:03:30,012] Trial 36 finished with value: 0.8197450070590654 and parameters: {'bagging_fraction': 0.7743980978468492, 'bagging_freq': 7}. Best is trial 34 with value: 0.8204180980263149.\n",
      "bagging, val_score: 0.820601: 100%|####################################################| 10/10 [00:37<00:00,  3.75s/it]\n",
      "feature_fraction_stage2, val_score: 0.820601:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.820760:  33%|############6                         | 1/3 [00:03<00:07,  3.51s/it][I 2023-12-18 03:03:33,535] Trial 37 finished with value: 0.8207598472741232 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.8207598472741232.\n",
      "feature_fraction_stage2, val_score: 0.820760:  33%|############6                         | 1/3 [00:03<00:07,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.820760:  67%|#########################3            | 2/3 [00:06<00:03,  3.45s/it][I 2023-12-18 03:03:36,937] Trial 38 finished with value: 0.820601079366891 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.8207598472741232.\n",
      "feature_fraction_stage2, val_score: 0.820760:  67%|#########################3            | 2/3 [00:06<00:03,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.820760: 100%|######################################| 3/3 [00:10<00:00,  3.43s/it][I 2023-12-18 03:03:40,343] Trial 39 finished with value: 0.820490915325128 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.8207598472741232.\n",
      "feature_fraction_stage2, val_score: 0.820760: 100%|######################################| 3/3 [00:10<00:00,  3.44s/it]\n",
      "regularization_factors, val_score: 0.820760:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:   5%|#9                                    | 1/20 [00:03<01:05,  3.44s/it][I 2023-12-18 03:03:43,792] Trial 40 finished with value: 0.8207119868035372 and parameters: {'lambda_l1': 0.0016156972736279455, 'lambda_l2': 4.486170821704178e-06}. Best is trial 40 with value: 0.8207119868035372.\n",
      "regularization_factors, val_score: 0.820760:   5%|#9                                    | 1/20 [00:03<01:05,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  10%|###8                                  | 2/20 [00:06<01:01,  3.43s/it][I 2023-12-18 03:03:47,223] Trial 41 finished with value: 0.8207119868035372 and parameters: {'lambda_l1': 0.001356237556067094, 'lambda_l2': 1.667350488781355e-06}. Best is trial 40 with value: 0.8207119868035372.\n",
      "regularization_factors, val_score: 0.820760:  10%|###8                                  | 2/20 [00:06<01:01,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  15%|#####7                                | 3/20 [00:10<00:58,  3.43s/it][I 2023-12-18 03:03:50,645] Trial 42 finished with value: 0.8207119160040245 and parameters: {'lambda_l1': 0.0014044463161734845, 'lambda_l2': 1.956322774769749e-06}. Best is trial 40 with value: 0.8207119868035372.\n",
      "regularization_factors, val_score: 0.820760:  15%|#####7                                | 3/20 [00:10<00:58,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  20%|#######6                              | 4/20 [00:13<00:54,  3.43s/it][I 2023-12-18 03:03:54,078] Trial 43 finished with value: 0.8207573692911786 and parameters: {'lambda_l1': 0.00246472049441158, 'lambda_l2': 2.121119699106816e-06}. Best is trial 43 with value: 0.8207573692911786.\n",
      "regularization_factors, val_score: 0.820760:  20%|#######6                              | 4/20 [00:13<00:54,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  25%|#########5                            | 5/20 [00:17<00:51,  3.44s/it][I 2023-12-18 03:03:57,533] Trial 44 finished with value: 0.8207119868035372 and parameters: {'lambda_l1': 0.0014889390277639588, 'lambda_l2': 1.9212667277512575e-06}. Best is trial 43 with value: 0.8207573692911786.\n",
      "regularization_factors, val_score: 0.820760:  25%|#########5                            | 5/20 [00:17<00:51,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  30%|###########4                          | 6/20 [00:20<00:48,  3.44s/it][I 2023-12-18 03:04:00,986] Trial 45 finished with value: 0.8207175091655279 and parameters: {'lambda_l1': 0.0021221516561150955, 'lambda_l2': 3.0194508513455096e-06}. Best is trial 43 with value: 0.8207573692911786.\n",
      "regularization_factors, val_score: 0.820760:  30%|###########4                          | 6/20 [00:20<00:48,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  35%|#############3                        | 7/20 [00:24<00:44,  3.44s/it][I 2023-12-18 03:04:04,420] Trial 46 finished with value: 0.8206993136907638 and parameters: {'lambda_l1': 0.00310594007875984, 'lambda_l2': 2.7938380873479734e-06}. Best is trial 43 with value: 0.8207573692911786.\n",
      "regularization_factors, val_score: 0.820760:  35%|#############3                        | 7/20 [00:24<00:44,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  40%|###############2                      | 8/20 [00:27<00:41,  3.44s/it][I 2023-12-18 03:04:07,851] Trial 47 finished with value: 0.8207129071972024 and parameters: {'lambda_l1': 0.0017416525008306625, 'lambda_l2': 2.897871557946112e-06}. Best is trial 43 with value: 0.8207573692911786.\n",
      "regularization_factors, val_score: 0.820760:  40%|###############2                      | 8/20 [00:27<00:41,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.820760:  45%|#################1                    | 9/20 [00:30<00:37,  3.42s/it][I 2023-12-18 03:04:11,236] Trial 48 finished with value: 0.8207292618846364 and parameters: {'lambda_l1': 0.27423543908471737, 'lambda_l2': 9.772083543684322e-05}. Best is trial 43 with value: 0.8207573692911786.\n",
      "regularization_factors, val_score: 0.820760:  45%|#################1                    | 9/20 [00:30<00:37,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821242:  50%|##################5                  | 10/20 [00:34<00:34,  3.43s/it][I 2023-12-18 03:04:14,690] Trial 49 finished with value: 0.8212423459531812 and parameters: {'lambda_l1': 6.874284203242162, 'lambda_l2': 0.02134805302882162}. Best is trial 49 with value: 0.8212423459531812.\n",
      "regularization_factors, val_score: 0.821242:  50%|##################5                  | 10/20 [00:34<00:34,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821621:  55%|####################3                | 11/20 [00:37<00:31,  3.44s/it][I 2023-12-18 03:04:18,164] Trial 50 finished with value: 0.8216209463473505 and parameters: {'lambda_l1': 9.42469829513506, 'lambda_l2': 0.03615412438833218}. Best is trial 50 with value: 0.8216209463473505.\n",
      "regularization_factors, val_score: 0.821621:  55%|####################3                | 11/20 [00:37<00:31,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821621:  60%|######################2              | 12/20 [00:41<00:27,  3.46s/it][I 2023-12-18 03:04:21,650] Trial 51 finished with value: 0.8215569081881123 and parameters: {'lambda_l1': 9.063422300165197, 'lambda_l2': 0.16427929000410277}. Best is trial 50 with value: 0.8216209463473505.\n",
      "regularization_factors, val_score: 0.821621:  60%|######################2              | 12/20 [00:41<00:27,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821621:  65%|########################             | 13/20 [00:44<00:24,  3.46s/it][I 2023-12-18 03:04:25,108] Trial 52 finished with value: 0.8215510318285582 and parameters: {'lambda_l1': 8.984250430442897, 'lambda_l2': 0.12064246278001842}. Best is trial 50 with value: 0.8216209463473505.\n",
      "regularization_factors, val_score: 0.821621:  65%|########################             | 13/20 [00:44<00:24,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821621:  70%|#########################9           | 14/20 [00:48<00:21,  3.55s/it][I 2023-12-18 03:04:28,857] Trial 53 finished with value: 0.8212818874810248 and parameters: {'lambda_l1': 7.200713975151955, 'lambda_l2': 0.1708662237356884}. Best is trial 50 with value: 0.8216209463473505.\n",
      "regularization_factors, val_score: 0.821621:  70%|#########################9           | 14/20 [00:48<00:21,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821621:  75%|###########################7         | 15/20 [00:52<00:17,  3.53s/it][I 2023-12-18 03:04:32,368] Trial 54 finished with value: 0.8213621741284279 and parameters: {'lambda_l1': 7.589805895475684, 'lambda_l2': 0.3788516212588455}. Best is trial 50 with value: 0.8216209463473505.\n",
      "regularization_factors, val_score: 0.821621:  75%|###########################7         | 15/20 [00:52<00:17,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821697:  80%|#############################6       | 16/20 [00:55<00:14,  3.52s/it][I 2023-12-18 03:04:35,853] Trial 55 finished with value: 0.8216969496242351 and parameters: {'lambda_l1': 9.926347819260023, 'lambda_l2': 0.2635745692891133}. Best is trial 55 with value: 0.8216969496242351.\n",
      "regularization_factors, val_score: 0.821697:  80%|#############################6       | 16/20 [00:55<00:14,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821697:  85%|###############################4     | 17/20 [00:58<00:10,  3.51s/it][I 2023-12-18 03:04:39,335] Trial 56 finished with value: 0.8215588197749553 and parameters: {'lambda_l1': 9.016553975286786, 'lambda_l2': 0.5216010790505546}. Best is trial 55 with value: 0.8216969496242351.\n",
      "regularization_factors, val_score: 0.821697:  85%|###############################4     | 17/20 [00:58<00:10,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821697:  90%|#################################3   | 18/20 [01:02<00:06,  3.49s/it][I 2023-12-18 03:04:42,791] Trial 57 finished with value: 0.8212841884651876 and parameters: {'lambda_l1': 6.411809428985145, 'lambda_l2': 7.065408544488419}. Best is trial 55 with value: 0.8216969496242351.\n",
      "regularization_factors, val_score: 0.821697:  90%|#################################3   | 18/20 [01:02<00:06,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821697:  95%|###################################1 | 19/20 [01:05<00:03,  3.48s/it][I 2023-12-18 03:04:46,238] Trial 58 finished with value: 0.8208009817910026 and parameters: {'lambda_l1': 0.5162610559998569, 'lambda_l2': 0.1704968621914819}. Best is trial 55 with value: 0.8216969496242351.\n",
      "regularization_factors, val_score: 0.821697:  95%|###################################1 | 19/20 [01:05<00:03,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.821697: 100%|#####################################| 20/20 [01:09<00:00,  3.46s/it][I 2023-12-18 03:04:49,669] Trial 59 finished with value: 0.8208065749525059 and parameters: {'lambda_l1': 0.510394987351807, 'lambda_l2': 0.26486567032529534}. Best is trial 55 with value: 0.8216969496242351.\n",
      "regularization_factors, val_score: 0.821697: 100%|#####################################| 20/20 [01:09<00:00,  3.47s/it]\n",
      "min_child_samples, val_score: 0.821697:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.821697:  20%|########8                                   | 1/5 [00:03<00:13,  3.45s/it][I 2023-12-18 03:04:53,131] Trial 60 finished with value: 0.8216969496242351 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.8216969496242351.\n",
      "min_child_samples, val_score: 0.821697:  20%|########8                                   | 1/5 [00:03<00:13,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.821697:  40%|#################6                          | 2/5 [00:06<00:10,  3.46s/it][I 2023-12-18 03:04:56,592] Trial 61 finished with value: 0.8216969496242351 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.8216969496242351.\n",
      "min_child_samples, val_score: 0.821697:  40%|#################6                          | 2/5 [00:06<00:10,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.821697:  60%|##########################4                 | 3/5 [00:10<00:06,  3.45s/it][I 2023-12-18 03:05:00,041] Trial 62 finished with value: 0.8216969496242351 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.8216969496242351.\n",
      "min_child_samples, val_score: 0.821697:  60%|##########################4                 | 3/5 [00:10<00:06,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.821697:  80%|###################################2        | 4/5 [00:13<00:03,  3.45s/it][I 2023-12-18 03:05:03,478] Trial 63 finished with value: 0.8216969496242351 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.8216969496242351.\n",
      "min_child_samples, val_score: 0.821697:  80%|###################################2        | 4/5 [00:13<00:03,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4610, number of negative: 16575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4662\n",
      "[LightGBM] [Info] Number of data points in the train set: 21185, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217607 -> initscore=-1.279668\n",
      "[LightGBM] [Info] Start training from score -1.279668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.821697: 100%|############################################| 5/5 [00:17<00:00,  3.45s/it][I 2023-12-18 03:05:06,924] Trial 64 finished with value: 0.8216969496242351 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.8216969496242351.\n",
      "min_child_samples, val_score: 0.821697: 100%|############################################| 5/5 [00:17<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\":\"binary\",\n",
    "    \"random_state\":57,\n",
    "    \"metric\":\"auc\"\n",
    "}\n",
    "\n",
    "lgb_clf_o = lgb_o.train(params, \n",
    "                        lgb_train, valid_sets=(lgb_train, lgb_val),\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "b97a4ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'random_state': 57,\n",
       " 'metric': 'auc',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 9.926347819260023,\n",
       " 'lambda_l2': 0.2635745692891133,\n",
       " 'num_leaves': 2,\n",
       " 'feature_fraction': 0.48000000000000004,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 20,\n",
       " 'num_iterations': 1000}"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf_o.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824aa14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
